{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "doc_folders = list(sorted(glob('../data/google/*/')))\n",
    "\n",
    "doc_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try with 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocrs = list(sorted(glob('../data/google/*/*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ocrs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_gramma(text):\n",
    "    \n",
    "    def o_rule(t):\n",
    "        return t.replace('ө', 'о')\n",
    "    \n",
    "    def lower(t):\n",
    "        return t.lower()\n",
    "    def some_rule(t):\n",
    "        return t\n",
    "    fs = [o_rule, some_rule, lower]\n",
    "\n",
    "    def apply(x):\n",
    "        for f in fs:\n",
    "            x = f(x)\n",
    "        return x\n",
    "    return [apply(t) for t in text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEAR_CONST = 15\n",
    "def near(y1, y2):\n",
    "    if np.abs(y1-y2) < NEAR_CONST:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def similar(seq1, seq2):\n",
    "    return difflib.SequenceMatcher(a=seq1.lower(), b=seq2.lower()).ratio() > SIMILARITY_CONST\n",
    "\n",
    "\n",
    "def check_text(list_of_substr, body):\n",
    "    if isinstance(list_of_substr, str):\n",
    "        list_of_substr = [list_of_substr.lower()]\n",
    "    else:\n",
    "        list_of_substr = [l.lower() for l in list_of_substr]\n",
    "    for b in body:\n",
    "        for substr in list_of_substr:\n",
    "            if substr in b:\n",
    "                return True\n",
    "    for b in body:\n",
    "        for substr in list_of_substr:\n",
    "            if similar(substr, b):\n",
    "                return True\n",
    "            \n",
    "    return False\n",
    "\n",
    "\n",
    "def make_rows(data):\n",
    "    data = data.sort_values(['upper_left_y', 'upper_left_x']).reset_index(drop=1)\n",
    "\n",
    "    data_post = list(enumerate(data.itertuples()))\n",
    "    result_rows = []\n",
    "    for pos, d in data_post:\n",
    "        _, prev_post = data_post[pos-1]\n",
    "        if near(prev_post.upper_left_y, d.upper_left_y):\n",
    "            result_rows[-1] += [d]\n",
    "        else:\n",
    "            result_rows += [[d]]\n",
    "    \n",
    "    # let's go through\n",
    "    result_text = []\n",
    "    for i, r in enumerate(result_rows):\n",
    "        result_rows[i] = list(sorted(r, key=lambda x: x.upper_left_x))\n",
    "        result_text.append(' '.join([t.text for t in result_rows[i]]))       \n",
    "            \n",
    "    return result_rows, result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! ../data/google/3_Разр. на ввод/10_0_g_ocr.csv\n"
     ]
    }
   ],
   "source": [
    "for o in ocrs:\n",
    "    df = pd.read_csv(o)\n",
    "    try:\n",
    "        txt = fix_gramma(make_rows(df))\n",
    "        if not check_text('РАЗРЕШЕНИЕ НА ВВОД ОБЪЕКТА В ЭКСПЛУАТАЦИЮ' , txt):\n",
    "            print(f'!!! {o}')\n",
    "            break\n",
    "    except:\n",
    "        print(len(df), o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(seq1, seq2):\n",
    "    return difflib.SequenceMatcher(a=seq1.lower(), b=seq2.lower()).ratio() > 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9122807017543859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar('ВВОД ОБЪЕКТА В ЭКСПЛУАТАЦИЮ', 'НА ВВОД ОБЪЕКТА В.ЭКСПЛУАТАЦИЮ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_doc(f):\n",
    "    df = pd.read_csv(f)\n",
    "    try:\n",
    "        txt = fix_gramma(make_rows(df))\n",
    "        if check_text('НА ВВОД ОБЪЕКТА В ЭКСПЛУАТАЦИЮ' , txt): # 3\n",
    "            return 'РАЗРЕШЕНИЕ НА ВВОД ОБЪЕКТА В ЭКСПЛУАТАЦИЮ'\n",
    "        elif check_text('ЭКСПЛИКАЦИЯ', txt): # 1 (2)\n",
    "             return 'ЭКСПЛИКАЦИЯ'\n",
    "        elif check_text('ТЕХНИЧЕСКИЙ ПАСПОРТ', txt): # 1 (1)\n",
    "            return 'ТЕХНИЧЕСКИЙ ПАСПОРТ'\n",
    "        elif check_text(['ДОГОВОР АРЕНДЫ ЗЕМЕЛЬНОГО УЧАСТКА', 'договор аренды земли'], txt): # 2\n",
    "            return 'ДОГОВОР АРЕНДЫ ЗЕМЕЛЬНОГО УЧАСТКА'\n",
    "        elif check_text(['разрешения на строительство', ], txt): # 4\n",
    "            return 'РАЗРЕШЕНИЕ НА СТРОИТЕЛЬСТВО'\n",
    "        elif check_text(['АРХИТЕКТУРНО-ГРАДОСТРОИТЕЛЬНОГО РЕШЕНИЯ', \n",
    "                         'АРХИТЕКТУРНО-ГРАДОСТРОИТЕЛЬНОЕ РЕШЕНИЕ'], txt): # 5\n",
    "            return 'СВИДЕТЕЛЬСТВО ОБ УТВЕРЖДЕНИИ АРХИТЕКТУРНО-ГРАДОСТРОИТЕЛЬНОГО РЕШЕНИЯ'\n",
    "    except:\n",
    "        return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = glob('../data/google/2_ЗУ/M_01_005599_05_06_1996 исправленное_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv( '../data/google/4_Разр. на стр-во/10_0_g_ocr.csv',\n",
    ")\n",
    "txt = fix_gramma(make_rows(df))\n",
    "\n",
    "check_text('НА ВВОД ОБЪЕКТА В ЭКСПЛУАТАЦИЮ' , txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doc.clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_docs(files):\n",
    "    fnames = set()\n",
    "    for f in files:\n",
    "        fnames.add(os.path.dirname(f) + '/' + os.path.basename(f).split('_')[0])\n",
    "    docs = dict.fromkeys(fnames)\n",
    "    for f in files:\n",
    "        f_name = os.path.dirname(f) + '/' + os.path.basename(f).split('_')[0]\n",
    "        docs[f_name] = check_doc(f) if (check_doc(f) is not None) else docs[f_name]\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_docs(files):\n",
    "    from collections import defaultdict\n",
    "\n",
    "    fnames = set()\n",
    "    for f in files:\n",
    "        fnames.add(os.path.dirname(f) + '/' + os.path.basename(f).split('_')[0])\n",
    "    docs = defaultdict(list)\n",
    "    for f in files:\n",
    "        f_name = os.path.dirname(f) + '/' + os.path.basename(f).split('_')[0]\n",
    "        docs[f_name].append(f)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = gather_docs(ocrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./all_docs.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for d, f in docs.items():\n",
    "    line = ''\n",
    "    for csv in f:\n",
    "        try:\n",
    "            _, rows = make_rows(pd.read_csv(csv))\n",
    "        except:\n",
    "            rows = ''\n",
    "        add = ' '.join(rows)\n",
    "        add += ' '\n",
    "        line += add\n",
    "    data[d] = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow_text\n",
    "\n",
    "UNIVERSAL_ENCODER = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./all_docs.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict.fromkeys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [00:41<00:00,  7.89it/s]\n"
     ]
    }
   ],
   "source": [
    "for k,v in tqdm(data.items()):\n",
    "    features[k] = UNIVERSAL_ENCODER([v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('features.npy', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'KMeans'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-9edcfd361119>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'KMeans'"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_e, two_e = UNIVERSAL_ENCODER([data['../data/google/1_БТИ/1. ул Шеногина, дом 3, строение 14 изм'], \n",
    "                                  data['../data/google/2_ЗУ/М-04-582527']])\n",
    "\n",
    "corr = np.inner(one_e, two_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_e.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3282603"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['../data/google/1_БТИ/1 изм']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_rows(pd.read_csv(docs['../data/google/1_БТИ/1 изм'][0]))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for k,v in docs:\n",
    "    data[k] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.4 s, sys: 492 ms, total: 45.9 s\n",
      "Wall time: 46.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ocrs = list(sorted(ocrs))\n",
    "res = (classify_docs(ocrs))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "od = collections.OrderedDict(sorted(res.items()))\n",
    "\n",
    "\n",
    "od = dict(od)\n",
    "\n",
    "for k,v in od.items():\n",
    "    if v is None:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
